{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:34.388568900Z",
     "start_time": "2025-04-09T08:28:33.873719100Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download and review the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "243c5ac431afecfd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:34.414392200Z",
     "start_time": "2025-04-09T08:28:34.386559Z"
    }
   },
   "id": "1831c66dd10f776a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 1797\n",
      ":Number of Attributes: 64\n",
      ":Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      ":Missing Attribute Values: None\n",
      ":Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      ":Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:34.433481300Z",
     "start_time": "2025-04-09T08:28:34.414392200Z"
    }
   },
   "id": "f35d050f6f952d1e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From description we see that dataset consist of 1797 instances. Each instance is a 8x8 image of a number, in dataset it represented like 64 atributes, each atribute has values in range from 0 to 16 that represent the color saturation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677c5be27c4576ce"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 4, 1, 7, 4, 8, 2, 2, 4, 4, 1, 9, 7, 3, 2, 1, 2, 5])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show each 100 target value\n",
    "digits.target[::100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:34.455933Z",
     "start_time": "2025-04-09T08:28:34.418991200Z"
    }
   },
   "id": "6537ec91a54d892b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how look our numbers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab2ec58b5fa83bba"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(12,4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sns.heatmap(digits.images[i], cmap=\"Greys\", ax=ax, cbar=False, square=True, xticklabels=False, yticklabels=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.285410400Z",
     "start_time": "2025-04-09T08:28:34.426840100Z"
    }
   },
   "id": "cee910ae04badaf7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creation a KNN model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf4b8badf6803981"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standard parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f182a0506c04857c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=11, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.299698400Z",
     "start_time": "2025-04-09T08:28:35.285410400Z"
    }
   },
   "id": "bc969483f976243a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First let's see how the standard model performs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b4b255e78c909"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.299698400Z",
     "start_time": "2025-04-09T08:28:35.294941200Z"
    }
   },
   "id": "1825c58e445d4209"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=3)",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-1 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div> </div></div></div></div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.317900900Z",
     "start_time": "2025-04-09T08:28:35.298689200Z"
    }
   },
   "id": "a0b3a388dc65942d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\КПІ\\Машинне навчання\\MachineLearningCourse\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\HP\\Desktop\\КПІ\\Машинне навчання\\MachineLearningCourse\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "predicted = knn.predict(X=X_test)\n",
    "expected = y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.581701900Z",
     "start_time": "2025-04-09T08:28:35.307646700Z"
    }
   },
   "id": "a22116dc82c40ab6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 9 9 3 1 4 1 5 0 4 9 4 1 5 3 3 8 5 6]\n",
      "[0 4 9 9 3 1 4 1 5 0 4 9 4 1 5 3 3 8 3 6]\n"
     ]
    }
   ],
   "source": [
    "print(predicted[:20])\n",
    "print(expected[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.602227800Z",
     "start_time": "2025-04-09T08:28:35.581701900Z"
    }
   },
   "id": "1784b05831a8d131"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9888888888888889"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.700516900Z",
     "start_time": "2025-04-09T08:28:35.590576Z"
    }
   },
   "id": "285f822609e3bd38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that score is quite good"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3289eddf14e32b26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see which images our model failed to recognize.\n",
    "For this I will create a dataframe with three columns: first column is a true value, second is whether our model recognise image, and third column is a predicted value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c35e939769e06ca"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "standard_knn = pd.DataFrame()\n",
    "standard_knn[\"Value\"] = expected\n",
    "standard_knn['IsTrue'] = [predicted[i] == expected[i] for i in range(len(predicted))]\n",
    "standard_knn['Predicted value'] = predicted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.701518100Z",
     "start_time": "2025-04-09T08:28:35.617841200Z"
    }
   },
   "id": "d5cf176341aef62f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "     Value  IsTrue  Predicted value\n0        0    True                0\n1        4    True                4\n2        9    True                9\n3        9    True                9\n4        3    True                3\n..     ...     ...              ...\n355      4    True                4\n356      4    True                4\n357      5    True                5\n358      7    True                7\n359      4    True                4\n\n[360 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n      <th>IsTrue</th>\n      <th>Predicted value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>4</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>4</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>7</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>4</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>360 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_knn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.720210400Z",
     "start_time": "2025-04-09T08:28:35.629834200Z"
    }
   },
   "id": "29951de49fab33c8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 3 \n",
      "Predicted value: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 200x200 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAttJREFUeJzt3aFNpFEYhtHLBgGSkGCogQaQWDyjaQE9lgIwUwgVYIYGQFIBCWjcv1m5dnPD8MyeU8A7I55c9+U/WJZlGRDza9d/AP6FcEkSLknCJUm4JAmXJOGSJFyShEvS4S5+9Ovra+re4+PjtK2Hh4dpW8/Pz9O2Li8vx0zb7XaUeXFJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JOzndmXlq88dqtRr77v39fdd/4Ufx4pIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES9LBsizLd//oT/5c1Mz7tbu7u2lb9/f3Y6ajo6NR5sUlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgk7cXpzvHx8bStk5OTaVufn5/TtvibF5ck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZK0k9Od2TabzbSt9Xo9bev09HTa1tPT05jp/Px8lHlxSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuSXtxuvNTvwh0cXExbevj42PM9PLykj4D8uKSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEvS4dgDM+/EXl9fp22dnZ1N23p7exszbbfbaVs3Nzfju3lxSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuSXvxuajNZjNta71eT9u6vb2dtnV9fT1murq6GmVeXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES9JenO7w//HikiRckoRLknBJEi5JwiVJuCQJlyThMop+A8GFXqQamAupAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 9 \n",
      "Predicted value: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 200x200 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAudJREFUeJzt3SFOJFEYRtFigmjLAmABrAIQJCAxSGwbtsFyWEKnPQKDxiAgBN+4Ygszk5cUt3POAr4ucfPcnz6Y53meIObP0h8A/0O4JAmXJOGSJFyShEuScEkSLknCJelwiR/9/v4eund1dTVsa7vdDttar9fDth4eHqaRjo6OpjIvLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJWmR053X19ehey8vL8O2drvdsK3NZjNs6+bmZhrp8fExfQbkxSVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJl6RFbs6enp6G7n19fQ3bWq1Ww7YuLi6Gbd3d3U0jvb+/D9tycwZ/SbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkLXK6M/KkZbTz8/NhW9vtdtjWer2eRjo9PZ3KvLgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZekg3me5ynu7e1t2NbJycmwrd1u9yv/DWgfeHFJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5Je3G681vPgC4vL4dtPT8/TyOt4qdAXlyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEk6XPoDfpvj4+NhW2dnZ8O2NpvNNNL19fVU5sUlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgk7cXpzu3t7bCtz8/PYVsfHx/Dtu7v74dt7QMvLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJelgnud56Y+Af+XFJUm4JAmXJOGSJFyShEuScEkSLknCZSr6AXWOTzUXcwblAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 9 \n",
      "Predicted value: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 200x200 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAsVJREFUeJzt3bFNJEEQQNHmhD8GBg7OOgSBCZlAKBAC7sZABggLjwAIAAMJCTKYEybmnVq3+/feC6A0I32VV+qjdV3XATG/dv0B8DeES5JwSRIuScIlSbgkCZck4ZIkXJKOxwF4fHycNuv+/n7arPf392mzbm9vx0yXl5ejzMYlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkHddPbb5dXV1Nm3V3dzdt1svLy17+47evr68xy7Is41+zcUkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJWknN2cfHx/jf/D09DRt1sXFxZhp2cGd2Ew2LknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJeloXdd1xN3c3Eyb9fDwMG3W5+fntFmvr69jpvPz81Fm45IkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJJ28urObNvtdi/PbTabzbRZ9VOb2WxckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRL0kG8uvP29jZt1tnZ2V6+lON05ycblyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckg7iuaiTk5Oxj05PT3f9CQfLxiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQdxOnO8/PztFnX19fTZi3LMm0WP9m4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXpKN1XdddfwT8KRuXJOGSJFyShEuScEkSLknCJUm4JAmXUfQbjD1DjAFyvBAAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 3 \n",
      "Predicted value: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 200x200 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAvBJREFUeJzt3bFJZGEYhtHrssEEwoCBycSCiblgBzZgCRYhmJmaGFmBYGARgnUY3VzBwOxuDbv868wznFPAywQPX3bnP1iWZZkg5te2fwD8C+GSJFyShEuScEkSLknCJUm4JAmXpN/THpjnedjW7e3tsK3X19dhW2dnZ9NIDw8Pw7Y2m83001xckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRL0sE2/vTu8/Nz6N7l5eWwrfPz82Fb19fXw7YeHx+nkd7f34dtvby8TD/NxSVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJl6S9eC7q9PR0J5+LWq/Xw7aOjo6Gbf2PvZ/m4pIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJK28lzULpvnedjW/f39tKvu7u6Gba1Wq+mnubgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZekvXh15/n5edjW1dXVtIs+Pj6G7q228LnNSC4uScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlaS8+3bm4uBi2NfIRopOTk2FbX19f00jr9Xoqc3FJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVpL74522w2w7a+v7+HbR0fHw/bOjw8HLa1D1xckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRL0lY+3Znneeje29vbsK2bm5thW09PT8O26s87jebikiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckg6WZVm2/SPgb7m4JAmXJOGSJFyShEuScEkSLknCJUm4TEV/AN2SSCHKzVGyAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in standard_knn.index:\n",
    "    if not standard_knn.loc[i, 'IsTrue']:\n",
    "        print(f\"True value: {standard_knn.Value[i]} \\n\"\n",
    "              f\"Predicted value: {standard_knn[\"Predicted value\"][i]}\")\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        sns.heatmap(X_test[i].reshape(8,8), cmap=\"Greys\", cbar=False, square=True, xticklabels=False, yticklabels=False)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.841626200Z",
     "start_time": "2025-04-09T08:28:35.652222400Z"
    }
   },
   "id": "aa17082a3f32e93d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From these images we see why model failed to recognise them, even for me it would be difficult "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f30f78df4833d10"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d4809b9d19784079"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also see more info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb2c97bc58f35d8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.952714200Z",
     "start_time": "2025-04-09T08:28:35.826945300Z"
    }
   },
   "id": "2cab51f4d2f20373"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_true=expected, y_pred=predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.952714200Z",
     "start_time": "2025-04-09T08:28:35.830458600Z"
    }
   },
   "id": "893fe1df3c6a5e8e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[38,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [ 0, 37,  0,  0,  0,  0,  0,  0,  0,  0],\n       [ 0,  0, 39,  0,  0,  0,  0,  0,  0,  0],\n       [ 0,  0,  0, 39,  0,  1,  0,  1,  0,  0],\n       [ 0,  0,  0,  0, 41,  0,  0,  0,  0,  0],\n       [ 0,  0,  0,  0,  0, 27,  0,  0,  0,  0],\n       [ 0,  0,  0,  0,  0,  0, 30,  0,  0,  0],\n       [ 0,  0,  0,  0,  0,  0,  0, 36,  0,  0],\n       [ 0,  0,  0,  0,  0,  0,  0,  0, 34,  0],\n       [ 0,  0,  0,  0,  1,  0,  0,  0,  1, 35]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.953714700Z",
     "start_time": "2025-04-09T08:28:35.835401400Z"
    }
   },
   "id": "c6e61023cc081679"
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to this confusion matrix, our model typically has problems with 3 and 9"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6497d6ef7f84ffba"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.977125200Z",
     "start_time": "2025-04-09T08:28:35.839448800Z"
    }
   },
   "id": "c8d6110fbf749aee"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "names = [str(digit) for digit in digits.target_names]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.978125900Z",
     "start_time": "2025-04-09T08:28:35.845139800Z"
    }
   },
   "id": "bb25d8e94be013ab"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       1.00      0.95      0.97        41\n",
      "           4       0.98      1.00      0.99        41\n",
      "           5       0.96      1.00      0.98        27\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       0.97      1.00      0.99        36\n",
      "           8       0.97      1.00      0.99        34\n",
      "           9       1.00      0.95      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(expected, predicted, target_names=names))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:35.978125900Z",
     "start_time": "2025-04-09T08:28:35.850427900Z"
    }
   },
   "id": "eb7fefcb1f61ba4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Non standard parameters "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24f7c09cecefad82"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1\n",
      "0.9861111111111112\n",
      "For 3\n",
      "0.9888888888888889\n",
      "For 5\n",
      "0.9861111111111112\n",
      "For 7\n",
      "0.9833333333333333\n",
      "For 9\n",
      "0.9833333333333333\n",
      "For 11\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "n_grid = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "for n in n_grid:\n",
    "    print(f\"For {n}\")\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(knn.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:36.369369100Z",
     "start_time": "2025-04-09T08:28:35.860373900Z"
    }
   },
   "id": "abf65df855fc5313"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the best result is with n=3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45224760ff1f188f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### More detailed parameter selection\n",
    "For this step I will use GridSearch to automatically search for the optimal model parameters.\n",
    "In GridSearch, I selected 4 parameters:\n",
    "\n",
    "**weights** - this parameter assigns greater weight to the nearest neighbors during decision-making\n",
    "**n_neighbors** - defines the number of neighbors to consider for voting (it’s better to choose an odd number to avoid ambiguity)\n",
    "**p** - selects the distance metric, such as Euclidean or Manhattan\n",
    "**leaf_size** - determines the leaf size of the tree, affecting the speed and structure of its construction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee90fcfa044e0188"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Best parameters found: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
      "Best cross-validation accuracy: 0.9847004452187379\n",
      "Test accuracy: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [10, 20, 30]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Test accuracy:\", best_model.score(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:45.726739400Z",
     "start_time": "2025-04-09T08:28:35.951703300Z"
    }
   },
   "id": "9b11f5738998ad97"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After GridSearch we got the best parameters for KNN model, but it didn't improve the accuracy of the model. I assume that this is because our model is already very accurate and the only data that remains is simply impossible to identify"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ea28caf1a4e9a12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing other models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eea231bae01aa9e0"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888888888888889\n",
      "0.8555555555555555\n",
      "0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "models = [SVC(kernel=\"poly\", degree=2), GaussianNB(), KNeighborsClassifier(n_neighbors=3)]\n",
    "\n",
    "for model in models:\n",
    "    current_model = model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T08:28:45.798153300Z",
     "start_time": "2025-04-09T08:28:45.726739400Z"
    }
   },
   "id": "a8eed4d5084950fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Other models also failed to improve results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "344cc684a5dab3bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
